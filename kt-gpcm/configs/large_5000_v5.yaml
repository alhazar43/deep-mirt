# large_5000_v5.yaml
#
# Cleanest test of scalar GPCM identifiability.
#
# Changes vs v3:
#   - theta_norm_weight: 0.5 (stronger unit-variance anchor)
#   - alpha_prior_weight: 0.0 (remove attractor toward alpha=1)
#
# Rationale:
#   v3 used theta_norm_weight=0.1 and alpha_prior_weight=0.02.
#   The alpha prior pulls log(alpha) → 0 (i.e., alpha → 1), reinforcing
#   collapse.  Removing it and strengthening the theta anchor gives alpha
#   the best chance to diversify based purely on the GPCM likelihood signal.

base:
  experiment_name: "large_5000_v5"
  device: "cuda"
  seed: 42

model:
  n_questions: 200
  n_categories: 5
  n_traits: 1
  memory_size: 100
  key_dim: 64
  value_dim: 128
  summary_dim: 50
  ability_scale: 1.0
  dropout_rate: 0.0
  memory_add_activation: "tanh"
  init_value_memory: true

training:
  epochs: 50
  batch_size: 64
  lr: 0.001
  grad_clip: 1.0
  focal_weight: 0.5
  weighted_ordinal_weight: 0.5
  ordinal_penalty: 0.5
  lr_patience: 10
  lr_factor: 0.9
  attention_entropy_weight: 0.0
  theta_norm_weight: 0.5
  alpha_prior_weight: 0.0
  beta_prior_weight: 0.0

data:
  data_dir: "data"
  dataset_name: "large_5000"
  train_split: 0.8
  min_seq_len: 10
